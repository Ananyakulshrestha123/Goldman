import dpkt
import socket
import math
import statistics
import numpy as np

def connection_id_to_str(cid, v=4):
    """This converts the connection ID cid which is a tuple of (source_ip_address, source_tcp_port, destination_ip_address,
    destination_tcp_port) to a string. v is either 4 for IPv4 or 6 for IPv6"""
    if v == 4:
        src_ip_addr_str = socket.inet_ntoa(cid[0])
        dst_ip_addr_str = socket.inet_ntoa(cid[2])
        return src_ip_addr_str + ":" + str(cid[1]) + "<=>" + dst_ip_addr_str + ":" + str(cid[3])
    elif v == 6:
        src_ip_addr_str = socket.inet_ntop(socket.AF_INET6, cid[0])
        dst_ip_addr_str = socket.inet_ntop(socket.AF_INET6, cid[2])
        return src_ip_addr_str + "." + str(cid[1]) + "<=>" + dst_ip_addr_str + "." + str(cid[3])
    else:
        raise ValueError('Argument to connection_id_to_str must be 4 or 6, is %d' % v)
 
def analyze_pcap_file(file_path):
    with open(file_path, 'rb') as f:
        pcap = dpkt.pcap.Reader(f)
        idx = 0
        flow_buckets = {}
        for ts, buf in pcap:
            if idx == 0:
                first_ts = ts
                idx = 1
            timestamp = ts - first_ts
            eth = dpkt.ethernet.Ethernet(buf)
            if eth.type != dpkt.ethernet.ETH_TYPE_IP:
                continue

            ip = eth.data
            if ip.p != dpkt.ip.IP_PROTO_TCP:
                continue
            
            total_duration=ts-first_ts
            tcp = ip.data
            connection_id = (ip.src, tcp.sport, ip.dst, tcp.dport)
            reverse_connection_id = (ip.dst, tcp.dport, ip.src, tcp.sport)

            flow = connection_id_to_str(connection_id)
            reverse_flow = connection_id_to_str(reverse_connection_id)
            
            if flow in flow_buckets:
                flow_buckets[flow].append([timestamp, 1, len(tcp.data), 1 if tcp.flags & dpkt.tcp.TH_FIN else 0])
            elif reverse_flow in flow_buckets:
                flow_buckets[reverse_flow].append([timestamp, -1, len(tcp.data), 1 if tcp.flags & dpkt.tcp.TH_FIN else 0])
            else:
                flow_buckets[flow] = [[timestamp, 1, len(tcp.data), 1 if tcp.flags & dpkt.tcp.TH_FIN else 0]]
                # Packet processing code

        No_of_windows = math.ceil(total_duration / window_size)

        window_buckets = [{} for _ in range(No_of_windows)]
        window_bins = [{'forward_bins': [], 'backward_bins': []} for _ in range(No_of_windows)]


        for flow, packets in flow_buckets.items():
            for packet in packets:
                timestamp, direction, data_length, fin_flag = packet
                window_index = math.floor(timestamp / window_size)
                bins = window_bins[window_index]
                if direction == 1:
                    bins['forward_bins'].extend([data_length] * math.ceil(data_length / 0.1))
                elif direction == -1:
                    bins['backward_bins'].extend([data_length] * math.ceil(data_length / 0.1))
                 
               
                           
                if flow not in window_buckets[window_index]:
                    window_buckets[window_index][flow] = {
                        'total_forward_packets': 0,
                        'total_backward_packets': 0,'total_bytes_per_sec': 0,
                        'forward_bytes': 0,
                        'backward_bytes': 0,
                        'forward_time':[],
                        'backward_time':[],
                        'forward_inter_arrival_time':[],
                        'backward_inter_arrival_time':[],
                        'flow_inter_arrival_time':[], 'forward_mean': 0,
                        'forward_min': 0, 'forward_max': 0,
                        'forward_std': 0, 'backward_mean': 0,                 
                        'backward_min': 0,'backward_max': 0,
                        'backward_std': 0,'flow_mean': 0,'flow_min': 0, 'flow_max': 0, 'flow_std': 0
                    }
                 
                flow_data = window_buckets[window_index][flow]
                bin_index = math.floor((timestamp - (window_index * window_size)) / 0.01)
                if direction == 1:
                    flow_data['total_forward_packets'] += 1
                    flow_data['forward_bytes'] += data_length
                    flow_data['forward_time'].append(timestamp)
                elif direction == -1:
                    flow_data['total_backward_packets'] += 1
                    flow_data['backward_bytes'] += data_length
                    flow_data['backward_time'].append(timestamp)
#             for idx, window in enumerate(window_buckets[:window_size]):
#                 for flow, flow_data in window.items():
                    
        for idx, window in enumerate(window_buckets[:window_size]):
                       
            for flow, flow_data in window.items():
                forward_time = flow_data['forward_time']
                backward_time = flow_data['backward_time']

                forward_interarrival_time = []
                backward_interarrival_time = []

                for i in range(1, len(forward_time)):
                    forward_interarrival_time.append(forward_time[i] - forward_time[i-1])

                for i in range(1, len(backward_time)):
                    backward_interarrival_time.append(backward_time[i] - backward_time[i-1])

            # Store the calculated interarrival times in the flow_data dictionary
                flow_data['forward_inter_arrival_time'] = forward_interarrival_time
                flow_data['backward_inter_arrival_time'] = backward_interarrival_time
                    
                merged_time = sorted(forward_time + backward_time)
                total_duration_of_flow= np.max(merged_time)-np.min(merged_time)
                total_bytes_per_sec = (flow_data['forward_bytes'] + flow_data['backward_bytes']) / total_duration_of_flow
                flow_data['total_bytes_per_sec'] = total_bytes_per_sec
                flow_inter_arrival_time = [merged_time[i] - merged_time[i - 1] for i in range(1, len(merged_time))  ]
                flow_data['flow_inter_arrival_time'] = flow_inter_arrival_time
                forward_interarrival_time = np.array(flow_data['forward_inter_arrival_time'])
                backward_interarrival_time = np.array(flow_data['backward_inter_arrival_time'])
                flow_interarrival_time = np.array(flow_data['flow_inter_arrival_time'])

                forward_mean = np.mean(forward_interarrival_time)
                forward_min = np.min(forward_interarrival_time)
                forward_max = np.max(forward_interarrival_time)
                forward_std = np.std(forward_interarrival_time)

                backward_mean = np.mean(backward_interarrival_time)
                backward_min = np.min(backward_interarrival_time)
                backward_max = np.max(backward_interarrival_time)
                backward_std = np.std(backward_interarrival_time)

                flow_mean = np.mean(flow_interarrival_time)
                flow_min = np.min(flow_interarrival_time)
                flow_max = np.max(flow_interarrival_time)
                flow_std = np.std(flow_interarrival_time)

                # Update flow_data with calculated statistics
                flow_data['forward_mean'] = forward_mean
                flow_data['forward_min'] = forward_min
                flow_data['forward_max'] = forward_max
                flow_data['forward_std'] = forward_std

                flow_data['backward_mean'] = backward_mean
                flow_data['backward_min'] = backward_min
                flow_data['backward_max'] = backward_max
                flow_data['backward_std'] = backward_std

                flow_data['flow_mean'] = flow_mean
                flow_data['flow_min'] = flow_min
                flow_data['flow_max'] = flow_max
                flow_data['flow_std'] = flow_std
  
    print("Flow Buckets:")
    print(flow_buckets)
    print('------------x---------------')
    print("Total Duration:", total_duration)
    print("Number of Windows:", No_of_windows)
    for idx, window in enumerate(window_buckets[:window_size]):
            print("Window", idx)
            for key,value in window.items():
                print( key)
                print(value)
    window_results = []
    for window_index, bins in enumerate(window_bins):
        window_results.append({
            'window_index': window_index,
            'forward_bins': bins['forward_bins'],
            'backward_bins': bins['backward_bins']
        })

    print("Window Bins:")
    for result in window_results:
        print("Window", result['window_index'])
        print("Forward Bins:", result['forward_bins'])
        print("Backward Bins:", result['backward_bins'])

window_size = 2
analyze_pcap_file('E:\PPT Reader\http_ipv4_complex.cap')



#The condition if flow_data['is_active'] == 0 checks if the flow is currently inactive (not active).
#If the flow is inactive, the following actions are performed:
#flow_data['is_active'] = 1 sets the is_active flag to 1, indicating that the flow is now active.
#The condition if (timestamp - flow_data['idle_start_time'] > 0) checks if there was an idle period before becoming active. If the time difference is greater than 0, it means there was an idle period.
#Inside the above condition, the idle duration is calculated by subtracting flow_data['idle_start_time'] from the current timestamp and appended to flow_data['idle'].
#flow_data['buffer_time'] = timestamp updates the buffer_time to the current timestamp.
#flow_data['active_start_time'] = timestamp updates the active_start_time to the current timestamp.
#If the flow is already active (flow_data['is_active'] != 0), the following actions are performed:
#flow_data['buffer_time'] = timestamp updates the buffer_time to the current timestamp.
#The subsequent code snippet iterates over the window_buckets and processes each flow within each window:
#The condition if hard_timeout < window_size*(idx+1) - flow_data['buffer_time'] checks if a hard timeout has occurred within the current window.
#If the hard timeout condition is met, the active duration is calculated by subtracting flow_data['active_start_time'] from the current timestamp, and it is appended to flow_data['active'].
#Otherwise, if the hard timeout condition is not met, the active duration is calculated as window_size*(idx+1) - flow_data['active_start_time'].
#In both cases, the idle duration is calculated as window_size*(idx+1) - hard_timeout - flow_data['buffer_start'] and appended to flow_data['idle'].


